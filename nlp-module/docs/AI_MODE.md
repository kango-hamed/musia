# ğŸ¤– Mode IA - Chatbot Musia avec Intelligence Artificielle

Le chatbot Musia fonctionne maintenant avec **l'IA complÃ¨te** (Groq LLM) mais **sans entrÃ©e vocale** pour le moment.

---

## ğŸ¯ Configuration Actuelle

### Mode ActivÃ© : Backend IA
```javascript
const USE_LOCAL_JSON = false;      // âœ… Backend IA activÃ©
const ENABLE_VOICE_INPUT = false;  // âš ï¸ EntrÃ©e vocale dÃ©sactivÃ©e
```

### FonctionnalitÃ©s Disponibles

| FonctionnalitÃ© | Statut | Description |
|----------------|--------|-------------|
| **RÃ©ponses IA** | âœ… ActivÃ© | Utilise Groq LLM (Llama 3.1-8b-instant) |
| **Chat Texte** | âœ… ActivÃ© | Questions/rÃ©ponses en temps rÃ©el |
| **Audio TTS** | âœ… ActivÃ© | RÃ©ponses audio avec Edge TTS |
| **Toutes les Å’uvres** | âœ… ActivÃ© | AccÃ¨s Ã  toute la base de donnÃ©es |
| **EntrÃ©e Vocale** | âŒ DÃ©sactivÃ© | Microphone dÃ©sactivÃ© temporairement |
| **Conversation Intelligente** | âœ… ActivÃ© | Contexte et mÃ©moire de conversation |

---

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- âœ… Python 3.11+
- âœ… ClÃ© API Groq (gratuite)
- âœ… Backend NLP configurÃ©

### Option 1 : Script Automatique (RecommandÃ©)

**Windows :**
```bash
START_CHATBOT_AI.bat
```

**macOS/Linux :**
```bash
./START_CHATBOT_AI.sh
```

Le script dÃ©marre automatiquement :
1. Backend NLP sur port 8000
2. Frontend sur port 3000
3. Ouvre le navigateur

### Option 2 : DÃ©marrage Manuel

**Terminal 1 - Backend NLP :**
```bash
cd nlp-module/backend-app
python run.py
```

**Terminal 2 - Frontend :**
```bash
cd nlp-module/frontend
python -m http.server 3000
```

**Navigateur :**
Visitez http://localhost:3000

---

## ğŸ’¬ DiffÃ©rences avec le Mode Local

### Mode Local (JSON)
- âš¡ RÃ©ponses instantanÃ©es (800ms simulÃ©)
- ğŸ“‹ RÃ©ponses basÃ©es sur mots-clÃ©s
- ğŸ’¾ 6 Å“uvres fixes en JSON
- ğŸ”Œ Fonctionne hors ligne
- ğŸ¯ RÃ©ponses scriptÃ©es

### Mode IA (Backend) - Actuel
- ğŸ¤– **RÃ©ponses intelligentes de l'IA**
- ğŸ’¡ Comprend le contexte et les nuances
- ğŸ—£ï¸ Conversations naturelles
- ğŸŒ AccÃ¨s Ã  toute la base de donnÃ©es
- ğŸ”Š Audio TTS pour chaque rÃ©ponse
- â±ï¸ Temps de rÃ©ponse : 1-3 secondes

---

## ğŸ¨ Exemple de Conversation avec IA

### Avec Mode Local (Keyword)
**Vous :** "Parle-moi de cette Å“uvre"
**Musia :** *[RÃ©ponse scriptÃ©e basique]*

### Avec Mode IA (Actuel)
**Vous :** "Parle-moi de cette Å“uvre et de son importance dans l'histoire africaine"
**Musia :** *[RÃ©ponse IA dÃ©taillÃ©e et contextuelle, gÃ©nÃ©rÃ©e par Groq LLM, tenant compte de l'histoire, la culture, l'art africain, etc.]*

**Vous :** "Pourquoi les artistes Edo utilisaient-ils cette technique ?"
**Musia :** *[RÃ©ponse IA expliquant les raisons historiques, culturelles et techniques, avec contexte]*

**Vous :** "Compare cette Å“uvre avec l'art europÃ©en de la mÃªme pÃ©riode"
**Musia :** *[Analyse comparative intelligente par l'IA]*

---

## âš™ï¸ Configuration Backend

### Fichier .env (nlp-module/backend-app/.env)

```bash
# API Groq (obligatoire)
GROQ_API_KEY=gsk_votre_clÃ©_groq_ici

# URL du backend principal (optionnel)
MUSIA_BACKEND_URL=http://localhost:3001/api
```

### Obtenir une ClÃ© Groq (Gratuit)

1. Visitez https://console.groq.com
2. CrÃ©ez un compte gratuit
3. GÃ©nÃ©rez une clÃ© API
4. Copiez dans `.env`

**Quota gratuit :**
- ğŸ†“ 14,400 requÃªtes/jour
- âš¡ TrÃ¨s rapide (Llama 3.1)
- ğŸ’¯ Suffisant pour dÃ©veloppement

---

## ğŸ”Š Audio Text-to-Speech

### Comment Ã§a marche

1. **Vous posez une question** (texte uniquement)
2. **Groq LLM gÃ©nÃ¨re la rÃ©ponse** en franÃ§ais
3. **Edge TTS convertit en audio** automatiquement
4. **Vous recevez :**
   - Texte de la rÃ©ponse (affichÃ© dans le chat)
   - Fichier audio MP3 (lecture automatique)

### ContrÃ´les Audio
- ğŸ”Š Lecture automatique pour la premiÃ¨re rÃ©ponse
- â–¶ï¸ Bouton play/pause pour les rÃ©ponses suivantes
- ğŸ” RÃ©Ã©couter Ã  volontÃ©

---

## ğŸ¤ Pourquoi l'EntrÃ©e Vocale est DÃ©sactivÃ©e ?

L'entrÃ©e vocale (microphone) est temporairement dÃ©sactivÃ©e pour :

1. **Simplifier l'utilisation** - Pas besoin de permissions micro
2. **Focus sur l'IA textuelle** - Tester d'abord les rÃ©ponses IA
3. **DÃ©veloppement progressif** - Activer la voix plus tard

### Pour Activer la Voix Plus Tard

Ã‰ditez `index.html` ligne 643 :
```javascript
const ENABLE_VOICE_INPUT = true;  // Activer l'entrÃ©e vocale
```

**Le microphone permettra alors :**
- ğŸ™ï¸ Enregistrement de questions vocales
- ğŸ”„ Transcription automatique (Whisper STT)
- ğŸ¤– RÃ©ponses IA comme d'habitude
- ğŸ”Š Audio TTS de la rÃ©ponse

---

## ğŸ“Š Architecture du Mode IA

```
Utilisateur tape une question
        â†“
Frontend (index.html)
        â†“
POST /conversation/text
        â†“
Backend NLP (FastAPI)
        â”œâ”€ Chargement du contexte de l'Å“uvre
        â”œâ”€ Classification de l'intention (NLP)
        â”œâ”€ Groq LLM (Llama 3.1-8b-instant)
        â”‚   â””â”€ GÃ©nÃ¨re rÃ©ponse intelligente en franÃ§ais
        â”œâ”€ Edge TTS
        â”‚   â””â”€ Convertit texte â†’ audio MP3
        â””â”€ Stockage conversation
        â†“
Retour Ã  Frontend
        â”œâ”€ Texte de la rÃ©ponse
        â””â”€ URL audio MP3
        â†“
Affichage + Lecture audio
```

---

## ğŸ§ª Test du Mode IA

### Checklist de Test

**Backend :**
- [ ] Backend dÃ©marre sur port 8000
- [ ] `curl http://localhost:8000/artworks` retourne JSON
- [ ] Groq API key configurÃ©e dans .env
- [ ] Pas d'erreurs dans les logs

**Frontend :**
- [ ] Page charge Ã  http://localhost:3000
- [ ] Å’uvres s'affichent dans la barre latÃ©rale
- [ ] Clic sur Å“uvre â†’ Message de bienvenue avec audio
- [ ] Taper question â†’ RÃ©ponse IA + audio
- [ ] Bouton microphone dÃ©sactivÃ© (message d'erreur)

**RÃ©ponses IA :**
- [ ] Questions simples â†’ RÃ©ponses appropriÃ©es
- [ ] Questions complexes â†’ Analyse dÃ©taillÃ©e
- [ ] Questions de suivi â†’ Contexte conservÃ©
- [ ] Comparaisons â†’ RÃ©ponses comparatives
- [ ] Questions hors-sujet â†’ Recentrage sur l'Å“uvre

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : "Ã‰chec du chargement des Å“uvres"

**Solution :**
1. VÃ©rifier backend : `curl http://localhost:8000/artworks`
2. VÃ©rifier `USE_LOCAL_JSON = false` dans index.html
3. RedÃ©marrer le backend

---

### ProblÃ¨me : RÃ©ponses en anglais au lieu du franÃ§ais

**Solution :**
Le backend doit Ãªtre configurÃ© pour rÃ©pondre en franÃ§ais.

VÃ©rifier dans `nlp-module/backend-app/app/services/llm.py` :
```python
system_prompt = """Tu es Musia, un guide musÃ©al AI qui parle franÃ§ais.
RÃ©ponds TOUJOURS en franÃ§ais, mÃªme si la question est en anglais."""
```

---

### ProblÃ¨me : Pas d'audio

**Solutions :**
1. VÃ©rifier que le navigateur n'est pas muet
2. Tester : `curl -X POST http://localhost:8000/test/tts -H "Content-Type: application/json" -d '{"text":"Bonjour"}'`
3. VÃ©rifier que Edge TTS est installÃ© : `pip list | grep edge-tts`

---

### ProblÃ¨me : Erreur "Groq API"

**Solutions :**
1. VÃ©rifier clÃ© API dans `.env`
2. VÃ©rifier quota : https://console.groq.com
3. Tester clÃ© : `curl https://api.groq.com/openai/v1/models -H "Authorization: Bearer gsk_..."`

---

## ğŸ“ˆ Performance

### Temps de RÃ©ponse Typique

- **Question simple :** 1-2 secondes
- **Question complexe :** 2-3 secondes
- **GÃ©nÃ©ration TTS :** +500ms-1s
- **Total :** 1.5-4 secondes

### Optimisations Possibles

1. **Cache LLM** - Stocker rÃ©ponses communes
2. **TTS prÃ©-gÃ©nÃ©rÃ©** - Pour messages de bienvenue
3. **Streaming** - Afficher rÃ©ponse au fur et Ã  mesure
4. **Queue** - GÃ©rer plusieurs requÃªtes simultanÃ©es

---

## ğŸ”„ Modes Disponibles

Le chatbot peut fonctionner en 3 modes :

### 1. Mode Local (JSON uniquement)
```javascript
USE_LOCAL_JSON = true
ENABLE_VOICE_INPUT = false
```
- âœ… Aucun backend nÃ©cessaire
- âš ï¸ RÃ©ponses scriptÃ©es

### 2. Mode IA sans Voix (Actuel)
```javascript
USE_LOCAL_JSON = false
ENABLE_VOICE_INPUT = false
```
- âœ… RÃ©ponses IA intelligentes
- âœ… Audio TTS
- âš ï¸ Pas d'entrÃ©e vocale

### 3. Mode IA Complet (Futur)
```javascript
USE_LOCAL_JSON = false
ENABLE_VOICE_INPUT = true
```
- âœ… RÃ©ponses IA intelligentes
- âœ… Audio TTS
- âœ… EntrÃ©e vocale (microphone)

---

## ğŸ¯ Prochaines Ã‰tapes

### Court Terme
- [ ] Tester rÃ©ponses IA en franÃ§ais
- [ ] Ajuster prompts systÃ¨me si nÃ©cessaire
- [ ] AmÃ©liorer temps de rÃ©ponse
- [ ] Ajouter plus d'Å“uvres Ã  la base

### Moyen Terme
- [ ] Activer l'entrÃ©e vocale
- [ ] Ajouter streaming des rÃ©ponses
- [ ] ImplÃ©menter cache LLM
- [ ] AmÃ©liorer gestion du contexte

### Long Terme
- [ ] Support multilingue complet
- [ ] PersonnalitÃ©s du guide (enfant/adulte/expert)
- [ ] Visites guidÃ©es automatiques
- [ ] Analytics des conversations

---

## ğŸ“š Documentation

- **Configuration :** Voir [QUICKSTART.md](QUICKSTART.md)
- **Mode Local :** Voir [LOCAL_MODE.md](LOCAL_MODE.md)
- **Questions FR :** Voir [QUESTIONS_FRANCAIS.md](QUESTIONS_FRANCAIS.md)
- **Backend NLP :** Voir `nlp-module/CLAUDE.md`

---

**Profitez du chatbot Musia avec intelligence artificielle complÃ¨te !** ğŸ¤–ğŸ¨âœ¨
