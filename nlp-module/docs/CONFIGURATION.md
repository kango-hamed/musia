# ‚öôÔ∏è Configuration du Chatbot Musia

## üìã R√©sum√© de la Configuration Actuelle

Le chatbot Musia est configur√© pour fonctionner en **Mode IA avec fichier JSON local**.

---

## üéØ Configuration Actuelle

### Variables de Configuration (index.html lignes 641-643)

```javascript
const API_URL = 'http://localhost:8000';
const USE_LOCAL_JSON = false;      // Mode IA activ√©
const ENABLE_VOICE_INPUT = false;  // Voix d√©sactiv√©e
```

### Source des ≈íuvres d'Art

**‚ö†Ô∏è IMPORTANT :** Le chatbot utilise **TOUJOURS** le fichier JSON local, m√™me en mode IA.

```javascript
// Le code charge TOUJOURS depuis artworks.json
const response = await fetch('./artworks.json');
```

**Fichier :** `nlp-module/frontend/artworks.json`

**Contenu :** 6 ≈ìuvres d'art africaines en fran√ßais
- La Plaque en Bronze du B√©nin
- T√™te en Terre Cuite Nok
- Masque Corporel Makonde
- Poids √† Or Ashanti
- Oiseau du Grand Zimbabwe
- Masque Royal Kuba

---

## üîÑ Deux Modes de Fonctionnement

### Mode 1 : Local (Keyword)
```javascript
const USE_LOCAL_JSON = true;
```
- ‚úÖ ≈íuvres : artworks.json
- ‚úÖ R√©ponses : Script√©es (keywords)
- ‚ùå Backend : Non requis
- ‚ùå Audio : Non

### Mode 2 : IA (Actuel)
```javascript
const USE_LOCAL_JSON = false;
```
- ‚úÖ ≈íuvres : **artworks.json** (toujours)
- ‚úÖ R√©ponses : **Groq LLM** (IA)
- ‚úÖ Backend : **Requis** (port 8000)
- ‚úÖ Audio : **Edge TTS**

---

## üé® Pourquoi Utiliser Toujours le JSON ?

### Avantages

1. **Coh√©rence des donn√©es** - M√™mes 6 ≈ìuvres en fran√ßais partout
2. **Pas de d√©pendance DB** - Pas besoin de base de donn√©es backend
3. **D√©marrage rapide** - Backend NLP suffit, pas de setup DB
4. **Contr√¥le total** - Vous ma√Ætrisez exactement quelles ≈ìuvres sont disponibles
5. **Performance** - Chargement instantan√© des ≈ìuvres

### Fonctionnement Hybride

```
≈íuvres d'art (artworks.json)
        ‚Üì
Frontend charge les 6 ≈ìuvres
        ‚Üì
Utilisateur s√©lectionne une ≈ìuvre
        ‚Üì
Frontend envoie question + contexte ≈ìuvre ‚Üí Backend NLP
        ‚Üì
Backend NLP (FastAPI)
  ‚îú‚îÄ Re√ßoit : question + donn√©es ≈ìuvre JSON
  ‚îú‚îÄ Groq LLM g√©n√®re r√©ponse intelligente
  ‚îú‚îÄ Edge TTS cr√©e audio
  ‚îî‚îÄ Retourne : r√©ponse IA + audio
        ‚Üì
Frontend affiche r√©ponse IA + audio
```

---

## üìä Comparaison des Modes

| Aspect | Mode Local | Mode IA (Actuel) |
|--------|------------|------------------|
| **≈íuvres** | artworks.json | artworks.json |
| **R√©ponses** | Keywords | ‚úÖ Groq LLM |
| **Audio** | ‚ùå | ‚úÖ Edge TTS |
| **Backend** | ‚ùå | ‚úÖ Port 8000 |
| **DB** | ‚ùå | ‚ùå |
| **Qualit√©** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üîß Pour Modifier les ≈íuvres

### √âditer le Fichier JSON

**Fichier :** `nlp-module/frontend/artworks.json`

```json
[
  {
    "id": "7",
    "code": "AFR007",
    "title": "Nouvelle ≈íuvre",
    "artist": "Artiste",
    "description": "Description compl√®te...",
    "period": "P√©riode historique",
    "style": "Style artistique",
    "collection": "Collection",
    "country": "Pays"
  }
]
```

**Recharger la page** et la nouvelle ≈ìuvre appara√Ætra !

---

## üéØ Configuration Backend NLP

### Fichier .env (nlp-module/backend-app/.env)

```bash
# Obligatoire pour le mode IA
GROQ_API_KEY=gsk_votre_cl√©_ici

# Optionnel
MUSIA_BACKEND_URL=http://localhost:3001/api
```

### Pas de Base de Donn√©es Requise !

Le backend NLP n'a **pas besoin** de base de donn√©es car :
- Les ≈ìuvres viennent du JSON frontend
- Les conversations sont en m√©moire
- Pas de persistence n√©cessaire pour l'IA

---

## üöÄ D√©marrage

### √âtape 1 : Backend NLP
```bash
cd nlp-module/backend-app
python run.py
```

### √âtape 2 : Frontend
```bash
cd nlp-module/frontend
python -m http.server 3000
```

### √âtape 3 : Test
1. Ouvrir http://localhost:3000
2. 6 ≈ìuvres africaines s'affichent (depuis JSON)
3. Cliquer sur une ≈ìuvre
4. Poser une question
5. Recevoir r√©ponse IA + audio

---

## üìù Flux de Donn√©es

### Chargement des ≈íuvres
```
1. Page charge
2. fetch('./artworks.json')
3. Affichage des 6 ≈ìuvres dans sidebar
```

### Conversation
```
1. Utilisateur s√©lectionne ≈ìuvre #1
2. Frontend lit donn√©es ≈ìuvre depuis artworksData
3. Frontend envoie √† backend :
   POST /conversation/start?artwork_id=1
4. Backend NLP :
   - Cr√©e session
   - G√©n√®re message bienvenue (IA)
   - G√©n√®re audio (TTS)
5. Frontend re√ßoit :
   - session_id
   - message (texte IA)
   - audio_url
6. Frontend affiche + joue audio
```

### Questions
```
1. Utilisateur tape question
2. Frontend envoie :
   POST /conversation/text
   {
     "session_id": "...",
     "message": "Question utilisateur",
     "artwork_context": { donn√©es de artworksData }
   }
3. Backend NLP :
   - Groq LLM g√©n√®re r√©ponse
   - Edge TTS cr√©e audio
4. Frontend re√ßoit :
   - response (texte IA)
   - audio_url
5. Affichage + lecture
```

---

## üîÑ Pour Passer √† une Base de Donn√©es

Si vous voulez utiliser une vraie base de donn√©es √† l'avenir :

### 1. Modifier loadArtworks()

```javascript
async function loadArtworks() {
    // Option 1 : JSON local (actuel)
    const response = await fetch('./artworks.json');

    // Option 2 : Backend API (futur)
    // const response = await fetch(`${API_URL}/artworks`);

    const artworks = await response.json();
    artworksData = artworks;
    // ...
}
```

### 2. Backend Doit Retourner Format JSON

Le backend devrait retourner le m√™me format :

```json
[
  {
    "id": "1",
    "title": "La Plaque en Bronze du B√©nin",
    "artist": "Artisans Edo",
    "description": "...",
    "period": "16√®me-17√®me si√®cle",
    "style": "Bronze du B√©nin",
    "collection": "Art d'Afrique de l'Ouest",
    "country": "Nigeria"
  }
]
```

---

## ‚úÖ V√©rification de la Configuration

### Checklist

- [ ] `index.html` ligne 642 : `USE_LOCAL_JSON = false`
- [ ] `index.html` ligne 643 : `ENABLE_VOICE_INPUT = false`
- [ ] `artworks.json` existe dans `nlp-module/frontend/`
- [ ] `artworks.json` contient 6 ≈ìuvres africaines en fran√ßais
- [ ] Backend NLP sur port 8000
- [ ] Frontend sur port 3000
- [ ] `.env` avec `GROQ_API_KEY`

### Test Rapide

```bash
# Test 1 : ≈íuvres JSON chargent
curl http://localhost:3000/artworks.json

# Test 2 : Backend NLP r√©pond
curl http://localhost:8000/

# Test 3 : Chatbot charge
# Ouvrir http://localhost:3000
# V√©rifier 6 ≈ìuvres dans sidebar
```

---

## üéâ R√©sum√©

**Configuration actuelle :**
- ‚úÖ ≈íuvres : JSON local (6 ≈ìuvres africaines)
- ‚úÖ R√©ponses : Groq LLM (IA)
- ‚úÖ Audio : Edge TTS
- ‚úÖ Langue : Fran√ßais
- ‚ùå Voix : D√©sactiv√©e
- ‚ùå Base de donn√©es : Non requise

**Avantage principal :**
Vous avez le **meilleur des deux mondes** :
- Simplicit√© du JSON (pas de DB √† g√©rer)
- Intelligence de l'IA (r√©ponses Groq)
- Audio professionnel (Edge TTS)

**Pour activer la voix plus tard :**
`ENABLE_VOICE_INPUT = true`

---

**Votre chatbot est configur√© pour une exp√©rience optimale !** üé®ü§ñ‚ú®
