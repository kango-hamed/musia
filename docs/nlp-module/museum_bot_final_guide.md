# ğŸ¤– Museum Guide Bot - Guide Complet d'Installation

## ğŸ“‹ Vue d'Ensemble

Ce guide vous permettra d'avoir un prototype fonctionnel en **3 heures** maximum.

**Stack Technique:**
- Backend: FastAPI + Python 3.10+
- STT: Faster-Whisper (gratuit, local)
- TTS: Edge-TTS (gratuit, Microsoft)
- NLP: Sentence Transformers + rÃ¨gles
- Base de donnÃ©es: SQLite

---

## ğŸš€ Installation Ã‰tape par Ã‰tape

### Ã‰tape 1: PrÃ©requis SystÃ¨me (10 min)

#### Installer Python 3.10+
```bash
# VÃ©rifier la version
python --version  # Doit Ãªtre >= 3.10

# Si pas installÃ©:
# Ubuntu/Debian
sudo apt update
sudo apt install python3.10 python3.10-venv python3-pip

# macOS (via Homebrew)
brew install python@3.10
```

#### Installer FFmpeg
```bash
# Ubuntu/Debian
sudo apt install ffmpeg

# macOS
brew install ffmpeg

# Windows
# TÃ©lÃ©charger depuis: https://ffmpeg.org/download.html
# Ajouter au PATH
```

#### VÃ©rifier l'installation
```bash
python --version   # 3.10 ou supÃ©rieur
ffmpeg -version    # Doit afficher des infos
```

---

### Ã‰tape 2: CrÃ©er le Projet (5 min)

```bash
# CrÃ©er le dossier principal
mkdir museum-guide-bot
cd museum-guide-bot

# CrÃ©er l'environnement virtuel
python -m venv venv

# Activer l'environnement
# Linux/Mac:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# VÃ©rifier activation (le prompt doit montrer (venv))
which python  # Doit pointer vers venv/bin/python
```

---

### Ã‰tape 3: Structure des Fichiers (5 min)

```bash
# CrÃ©er l'arborescence
mkdir -p backend/app/{api,services,utils}
mkdir -p data/{uploads,tts_cache}
mkdir -p frontend

# CrÃ©er les fichiers __init__.py
touch backend/app/__init__.py
touch backend/app/api/__init__.py
touch backend/app/services/__init__.py
touch backend/app/utils/__init__.py

# CrÃ©er les fichiers de configuration
touch .env
touch .gitignore
```

**Structure finale:**
```
museum-guide-bot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ stt.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tts.py
â”‚   â”‚   â”‚   â”œâ”€â”€ nlp.py
â”‚   â”‚   â”‚   â””â”€â”€ knowledge.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ __init__.py
â”‚   â””â”€â”€ run.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ artworks.json
â”‚   â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ tts_cache/
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ init_db.py
â”œâ”€â”€ download_models.py
â”œâ”€â”€ check_installation.py
â”œâ”€â”€ test_api.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

### Ã‰tape 4: Fichier requirements.txt (5 min)

CrÃ©er `requirements.txt`:
```txt
# Backend Framework
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-multipart==0.0.6
websockets==12.0

# Audio Processing
faster-whisper==0.10.0
edge-tts==6.1.9
pydub==0.25.1
numpy==1.26.3

# NLP
scikit-learn==1.4.0
sentence-transformers==2.3.1
nltk==3.8.1

# Database
sqlalchemy==2.0.25
aiosqlite==0.19.0

# Utilities
python-dotenv==1.0.0
pydantic==2.5.3
pydantic-settings==2.1.0
aiofiles==23.2.1

# Dev/Test
pytest==7.4.4
pytest-asyncio==0.23.3
httpx==0.26.0
aiohttp==3.9.1
```

**Installer les dÃ©pendances:**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

â±ï¸ **DurÃ©e:** 5-10 minutes (selon connexion Internet)

---

### Ã‰tape 5: Fichier .env (2 min)

CrÃ©er `.env`:
```bash
# Application
APP_NAME="Museum Guide Bot"
APP_VERSION="1.0.0"
DEBUG=True

# API
API_HOST=0.0.0.0
API_PORT=8000

# Database
DATABASE_URL=sqlite:///./data/museum.db

# Audio
MAX_AUDIO_LENGTH=30
AUDIO_SAMPLE_RATE=16000

# STT
WHISPER_MODEL=base
WHISPER_DEVICE=cpu
WHISPER_COMPUTE_TYPE=int8

# TTS
TTS_VOICE=fr-FR-DeniseNeural
TTS_RATE=+0%
TTS_VOLUME=+0%

# NLP
INTENT_CONFIDENCE_THRESHOLD=0.6
MAX_RESPONSE_LENGTH=300
CONVERSATION_TIMEOUT=30

# Cache
ENABLE_CACHE=True
CACHE_TTL=3600
```

---

### Ã‰tape 6: Copier le Code (20 min)

Copiez les fichiers depuis les artifacts fournis prÃ©cÃ©demment:

1. **backend/app/main.py** - Application FastAPI
2. **backend/app/models.py** - ModÃ¨les Pydantic
3. **backend/app/config.py** - Configuration
4. **backend/app/services/stt.py** - Speech-to-Text
5. **backend/app/services/tts.py** - Text-to-Speech
6. **backend/app/services/nlp.py** - NLP
7. **backend/app/services/knowledge.py** - Base de connaissances
8. **backend/app/services/__init__.py** - Exports
9. **backend/run.py** - Script de dÃ©marrage
10. **data/artworks.json** - DonnÃ©es des Å“uvres
11. **init_db.py** - Initialisation DB
12. **download_models.py** - TÃ©lÃ©chargement modÃ¨les
13. **check_installation.py** - VÃ©rification
14. **test_api.py** - Tests
15. **frontend/index.html** - Interface web

---

### Ã‰tape 7: VÃ©rifier l'Installation (5 min)

```bash
# VÃ©rifier tout
python check_installation.py
```

**Sortie attendue:**
```
ğŸ” Checking Museum Guide Bot Installation
============================================================
âœ… Python 3.10.x
âœ… FFmpeg version x.x
âœ… FastAPI
âœ… Faster-Whisper
âœ… Edge-TTS
âœ… Sentence-Transformers
... etc ...
âœ… Installation complete! Ready to run.
```

---

### Ã‰tape 8: TÃ©lÃ©charger les ModÃ¨les (10 min)

```bash
# TÃ©lÃ©charger Whisper, Sentence-Transformers, NLTK data
python download_models.py
```

**Taille totale:** ~2.5 GB

â±ï¸ **DurÃ©e:** 5-15 minutes (selon connexion)

---

### Ã‰tape 9: Initialiser la Base de DonnÃ©es (2 min)

```bash
# CrÃ©er la DB et insÃ©rer les Å“uvres
python init_db.py
```

**Sortie attendue:**
```
ğŸ—„ï¸  Initializing database...
âœ… Loaded 3 artworks from JSON
âœ… Table 'artworks' created
âœ… Table 'conversations' created
  âœ“ La Joconde by LÃ©onard de Vinci
  âœ“ La Nuit Ã‰toilÃ©e by Vincent van Gogh
  âœ“ Guernica by Pablo Picasso

âœ¨ Database initialized successfully!
```

---

### Ã‰tape 10: Lancer le Serveur (1 min)

```bash
cd backend
python run.py
```

**Sortie attendue:**
```
ğŸš€ Starting Museum Guide Bot API...
ğŸ“ API: http://localhost:8000
ğŸ“š Docs: http://localhost:8000/docs
ğŸŒ Frontend: http://localhost:8000/index.html

INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

---

### Ã‰tape 11: Tester l'API (5 min)

#### Dans un autre terminal:

```bash
# Activer l'environnement
source venv/bin/activate  # ou venv\Scripts\activate

# Tester
python test_api.py
```

**Sortie attendue:**
```
ğŸ§ª Starting API Tests...
============================================================
âœ… PASS - Health Check
âœ… PASS - Artworks List
âœ… PASS - Conversation Flow
âœ… PASS - Text-to-Speech
============================================================
Result: 4/4 tests passed
ğŸ‰ All tests passed!
```

---

### Ã‰tape 12: Interface Web (2 min)

1. Ouvrir un navigateur
2. Aller Ã : `http://localhost:8000/docs` (Swagger UI)
3. Copier `frontend/index.html` dans `backend/app/static/`
4. Ou ouvrir directement le fichier HTML dans le navigateur

**Interface fonctionnelle:**
- Liste des Å“uvres Ã  gauche
- Chat au centre
- PossibilitÃ© de poser des questions
- Audio gÃ©nÃ©rÃ© automatiquement

---

## ğŸ§ª Tests Rapides

### Test 1: Health Check
```bash
curl http://localhost:8000/health
```

### Test 2: Lister les Å“uvres
```bash
curl http://localhost:8000/artworks | jq
```

### Test 3: Conversation complÃ¨te
```bash
# DÃ©marrer
SESSION=$(curl -s -X POST "http://localhost:8000/conversation/start?artwork_id=mona-lisa" | jq -r '.session_id')

# Poser une question
curl -X POST http://localhost:8000/conversation/text \
  -H "Content-Type: application/json" \
  -d "{\"session_id\":\"$SESSION\",\"message\":\"Pourquoi sourit-elle?\"}" | jq
```

---

## ğŸ¯ DÃ©mo pour le Hackathon

### ScÃ©nario de DÃ©monstration

1. **Montrer l'interface web** (30 sec)
2. **SÃ©lectionner une Å“uvre** - La Joconde (10 sec)
3. **DÃ©marrer la visite** - Ã‰couter la prÃ©sentation (30 sec)
4. **Poser 2-3 questions:**
   - "Pourquoi sourit-elle ?"
   - "Qui est cette femme ?"
   - "Quelle technique a Ã©tÃ© utilisÃ©e ?"
5. **Montrer les rÃ©ponses audio** (1 min)
6. **Changer d'Å“uvre** - La Nuit Ã‰toilÃ©e (30 sec)
7. **Expliquer l'architecture** (1 min)

**DurÃ©e totale:** 4 minutes

---

## ğŸ› RÃ©solution des ProblÃ¨mes Courants

### ProblÃ¨me: Port 8000 dÃ©jÃ  utilisÃ©
```bash
# Changer le port dans backend/run.py
port=8001  # Au lieu de 8000
```

### ProblÃ¨me: ModÃ¨les trop lents
```bash
# Utiliser un modÃ¨le plus petit dans .env
WHISPER_MODEL=tiny  # Au lieu de base
```

### ProblÃ¨me: FFmpeg introuvable
```bash
# VÃ©rifier le PATH
which ffmpeg

# RÃ©installer si nÃ©cessaire
sudo apt install --reinstall ffmpeg
```

### ProblÃ¨me: Import Error
```bash
# RÃ©installer les dÃ©pendances
pip install -r requirements.txt --force-reinstall
```

### ProblÃ¨me: Latence trop Ã©levÃ©e
**Solution:** PrÃ©-gÃ©nÃ©rer les audios des narrations
```python
# Ajouter dans init_db.py
async def pregenerate_audio():
    from backend.app.services import TTSService
    tts = TTSService()
    for artwork in artworks:
        narrative = artwork['narratives']['short']
        await tts.synthesize(narrative)
```

---

## ğŸ“Š Performance Attendue

| Composant | Latence | QualitÃ© |
|-----------|---------|---------|
| STT (5s audio) | ~1s | Excellente |
| NLP (classification) | ~100ms | Bonne |
| FAQ Matching | ~200ms | TrÃ¨s bonne |
| TTS (cache hit) | ~50ms | Excellente |
| TTS (cache miss) | ~800ms | Excellente |
| **Total (cached)** | **~1.5s** | - |
| **Total (uncached)** | **~2.5s** | - |

---

## ğŸš€ AmÃ©liorations Possibles (aprÃ¨s le hackathon)

1. **Streaming Audio** - RÃ©duire latence perÃ§ue
2. **Multi-langues** - DÃ©tecter automatiquement la langue
3. **Base vectorielle** - Meilleur matching sÃ©mantique
4. **Vision** - DÃ©tecter quelle Å“uvre le visiteur regarde
5. **Personnalisation** - Adapter le niveau de dÃ©tail
6. **Analytics** - Dashboard admin avec stats

---

## ğŸ“š Ressources

- **FastAPI Docs:** https://fastapi.tiangolo.com
- **Faster-Whisper:** https://github.com/guillaumekln/faster-whisper
- **Edge-TTS:** https://github.com/rany2/edge-tts
- **Sentence-Transformers:** https://www.sbert.net

---

## ğŸ‰ Checklist Finale

- [ ] Python 3.10+ installÃ©
- [ ] FFmpeg installÃ©
- [ ] Environnement virtuel crÃ©Ã©
- [ ] DÃ©pendances installÃ©es
- [ ] Structure fichiers crÃ©Ã©e
- [ ] Code copiÃ©
- [ ] ModÃ¨les tÃ©lÃ©chargÃ©s
- [ ] Base de donnÃ©es initialisÃ©e
- [ ] Serveur lancÃ©
- [ ] Tests passent
- [ ] Interface web fonctionne
- [ ] Audio gÃ©nÃ©rÃ© correctement

**Si tout est cochÃ© â†’ Vous Ãªtes prÃªt pour le hackathon ! ğŸš€**

---

## ğŸ’¡ Conseils pour le Pitch

1. **Commencer par le problÃ¨me**: Visites de musÃ©e peu engageantes
2. **DÃ©monstration live**: Montrer l'interaction naturelle
3. **Technique simple mais efficace**: Pas de GPU, pas de coÃ»ts
4. **ScalabilitÃ©**: Facile d'ajouter des Å“uvres
5. **Open source**: Tout est gratuit et accessible

**Bonne chance ! ğŸ€**
